"""


2023-05-30 Linus A. Hein
"""
from typing import Union

import numpy as np
from matplotlib import pyplot as plt
from scipy.optimize import curve_fit
from scipy.special import logsumexp

from applications.data_handling import read_data, read_metadata_json, convert_dataframe_to_numpy


def func_4PLb1_ln(T, lower, upper, *log_K_D):
    """
    Adapted 4PL function for fitting two target concentrations at the same time.
    https://www.biolegend.com/en-us/blog/curve-fitting-for-immunoassays-legendplex
    Setting b=1.

    :param T: (n, ...) numpy array of natural logarithms of n target concentrations.
    :param lower: lower bound on reads.
    :param upper: upper bound on reads.
    :parma log_K_D: tuple of natural logarithms of the K_D values of the m affinity reagents.
    :return: (...) reads generated by the samples. Returns same shape as target concentrations.
    """
    assert len(log_K_D) == T.shape[0]
    tmp = logsumexp([T[i] - log_K_Di for i, log_K_Di in enumerate(log_K_D)], axis=0)
    return upper + (lower - upper) / (1 + np.exp(tmp))


def normalize_reads(reads: np.array,
                    lower_bounds: Union[float, np.ndarray],
                    upper_bounds: Union[float, np.ndarray],
                    std=False) -> np.ndarray:
    """
    Normalize reads to be in a range between [0;1] using given lower and upper bounds. If there is
    an outlier, the outlier will NOT be truncated to lie within the range.

    2023-06-01 Linus A. Hein.

    :param reads: (m, ...) Unnormalized readouts (for example from a real-world measurement).
    :param lower_bounds: scalar or (m, ) Lowest value we expect from the readout.
    :param upper_bounds: scalar or (m, ) Largest value we expect from the readout.
    :param std: boolean (default=False). Whether we are normalizing a standard deviation.
    :return: (m, ...) Normalized readouts (ideally in range [0;1]).
    """
    if isinstance(lower_bounds, np.ndarray):
        assert lower_bounds.shape[0] == reads.shape[0]
    if isinstance(upper_bounds, np.ndarray):
        assert upper_bounds.shape[0] == reads.shape[0]
    if std:
        return (reads) / np.abs(upper_bounds - lower_bounds)[:, np.newaxis]
    return (reads - lower_bounds[:, np.newaxis]) / (upper_bounds - lower_bounds)[:, np.newaxis]


def denormalize_reads(reads: np.array,
                      lower_bounds: Union[float, np.ndarray],
                      upper_bounds: Union[float, np.ndarray],
                      std=False) -> np.ndarray:
    """
    Denormalize reads from a range between [0;1] to given lower and upper bounds.

    2023-06-01 Linus A. Hein.

    :param reads: (m, ...) Normalized readouts (ideally in range [0;1]).
    :param lower_bounds: scalar or (m, ) Lowest value we expect from the readout.
    :param upper_bounds: scalar or (m, ) Largest value we expect from the readout.
    :param std: boolean (default=False). Whether we are normalizing a standard deviation.
    :return: (m, ...) Denormalized readouts that you would expect from your readout.
    """
    if isinstance(lower_bounds, np.ndarray):
        assert lower_bounds.shape[0] == reads.shape[0]
    if isinstance(upper_bounds, np.ndarray):
        assert upper_bounds.shape[0] == reads.shape[0]

    if std:
        return reads * np.abs(upper_bounds - lower_bounds)[:, np.newaxis]
    return reads * (upper_bounds - lower_bounds)[:, np.newaxis] + lower_bounds[:, np.newaxis]


def fit_multi_KD(concentrations, reads, uncertainty=False):
    """
    Fits a generalized (cross-reactive) 4PL curve to the given data. Optimizes the following loss
    function:

    loss = ||reads - func_4PLb1_ln(concs, lower, upper, *ln_K_D)||_2^2

    :param concentrations: (n, k) concentrations of n targets across k samples.
    :param reads: (m, k) reads generated by m affinity reagents across k samples.
    :param uncertainty: boolean. Whether to return uncertainty values.

    :return: tuple:
        (m, n) K_D matrix,
        (m) lower bounds,
        (m) upper bounds,
        (m, n) (optional) K_D matrix standard deviations,
        (m) (optional) lower bounds standard deviations,
        (m) (optional) upper bounds standard deviations
    """
    n, k = concentrations.shape
    m = reads.shape[0]
    lower_bounds = np.zeros(m)
    upper_bounds = np.zeros(m)
    K_D_matrix = np.zeros((m, n))

    lower_bounds_std = np.zeros_like(lower_bounds)
    upper_bounds_std = np.zeros_like(upper_bounds)
    K_D_matrix_std = np.zeros_like(K_D_matrix)

    log_concs = np.log(concentrations)

    for reagent_ind in range(m):
        reagent_reads = reads[reagent_ind, :]
        fit_result = curve_fit(func_4PLb1_ln, log_concs, reagent_reads,
                               p0=(np.min(reagent_reads) / 2, np.max(reagent_reads) * 2) + (
                                   -4,) * n, check_finite=False)
        popt = fit_result[0]
        pcov = fit_result[1]
        perr = np.sqrt(np.diag(pcov))  # calculate standard deviations as per documentation
        lower_bounds[reagent_ind] = popt[0]
        lower_bounds_std[reagent_ind] = perr[0]
        upper_bounds[reagent_ind] = popt[1]
        upper_bounds_std[reagent_ind] = perr[1]
        K_D_matrix[reagent_ind, :] = np.exp(popt[2:])
        K_D_matrix_std[reagent_ind, :] = perr[2:] / np.log(10)  # convert from ln to log10

    if uncertainty:
        return K_D_matrix, lower_bounds, upper_bounds
    return K_D_matrix, lower_bounds, upper_bounds, \
        K_D_matrix_std, lower_bounds_std, upper_bounds_std


if __name__ == '__main__':
    # load data
    metadata = read_metadata_json('/Users/linus/workspace/cr_quant/data/2023_05_22_CR8.json')
    df = read_data('/Users/linus/workspace/cr_quant/data/2023_05_22_CR8_combined_2colreads.csv',
                   metadata)
    # only use data where only one of the target concentrations is non-zero
    criterion = df.singleplex
    view = df[criterion]

    # convert from dataframe to numpy arrays
    concs, reads = convert_dataframe_to_numpy(view, metadata)

    aptamer_names = [reagent['display_name'] for reagent in metadata['reagents']]
    target_names = [target['display_name'] for target in metadata['targets']]

    # fit cross-reactive 4PL curve
    K_D_matrix, lower_bounds, upper_bounds, \
        K_D_matrix_std, lower_bounds_std, upper_bounds_std = fit_multi_KD(concs, reads)

    # plot the fitted curves
    fig, axs = plt.subplots(nrows=len(aptamer_names), ncols=len(target_names),
                            sharey='row', sharex='col')

    for apt_ind, apt_name in enumerate(aptamer_names):
        print(apt_name)
        print(f'\tlower bound: \t{lower_bounds[apt_ind]:.1f} +- {lower_bounds_std[apt_ind]:.1f}')
        print(f'\tupper bound: \t{upper_bounds[apt_ind]:.1f} +- {upper_bounds_std[apt_ind]:.1f}')
        for target_ind, target_name in enumerate(target_names):
            print(f'\tlog10(K_D) against {target_name}: \t'
                  f'{np.log10(K_D_matrix[apt_ind, target_ind]):.3f} '
                  f'+- {K_D_matrix_std[apt_ind, target_ind]:.3f}')

            ax = axs[apt_ind, target_ind]
            relevant_sample_inds = concs[target_ind, :] > 0

            target_concs = concs[target_ind, relevant_sample_inds]
            apt_reads = reads[apt_ind, relevant_sample_inds]

            ax.scatter(target_concs, apt_reads)
            x_coors = np.logspace(np.log10(np.min(target_concs)) - 1,
                                  np.log10(np.max(target_concs)) + 1,
                                  1000)
            ax.plot(x_coors, func_4PLb1_ln(np.log(x_coors[np.newaxis, :]),
                                           lower_bounds[apt_ind],
                                           upper_bounds[apt_ind],
                                           np.log(K_D_matrix[apt_ind, target_ind])))
            ax.set_xlabel(target_name)
            ax.set_xscale('log')
            ax.set_title(apt_name)
            ax.set_ylabel('signal')
            ax.grid()
    plt.show()
